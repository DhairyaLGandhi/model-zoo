{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating registry at `~/.julia/registries/General`\n",
      "  Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h  Updating git-repo `https://github.com/FluxML/Flux.jl.git`\n",
      "\u001b[?25l    Fetching: [>                                        ]  0.0 %\r\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/notebooks/vision/mnist/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/notebooks/vision/mnist/Manifest.toml`\n",
      " [no changes]\n",
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "│   exception = ErrorException(\"Required dependency Juno [e5e0dc1b-0480-54bc-9374-aad01c23163d] failed to load from a cache file.\")\n",
      "└ @ Base loading.jl:969\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate(); Pkg.add(PackageSpec(name=\"Flux\", rev = \"master\"))\n",
    "\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "using CuArrays"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Classify MNIST digits with a simple multi-layer-perceptron"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60000-element Array{Array{ColorTypes.Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}:\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n ⋮                                                                                                                                                                                                                                                                               \n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "imgs = MNIST.images()"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Stack images into one large batch"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60000-element Array{Int64,1}:\n 5\n 0\n 4\n 1\n 9\n 2\n 1\n 3\n 1\n 4\n ⋮\n 2\n 9\n 5\n 1\n 8\n 3\n 5\n 6\n 8"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "\n",
    "labels = MNIST.labels()"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "One-hot-encode the labels"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: ADAM(params) is deprecated; use ADAM(η::Float64) instead\n",
      "│   caller = top-level scope at none:0\n",
      "└ @ Core none:0\n",
      "┌ Info: starting training..\n",
      "└ @ Main.##360 string:16\n",
      "┌ Warning: train!(loss, data, opt) is deprecated; use train!(loss, params, data, opt) instead\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n",
      "loss(X, Y) = 2.3894427f0 (tracked)\n",
      "loss(X, Y) = 2.1580908f0 (tracked)\n",
      "loss(X, Y) = 1.9806883f0 (tracked)\n",
      "loss(X, Y) = 1.8056185f0 (tracked)\n",
      "loss(X, Y) = 1.6421576f0 (tracked)\n",
      "loss(X, Y) = 1.4961658f0 (tracked)\n",
      "loss(X, Y) = 1.3667434f0 (tracked)\n",
      "loss(X, Y) = 1.2496492f0 (tracked)\n",
      "loss(X, Y) = 1.1401035f0 (tracked)\n",
      "loss(X, Y) = 1.0379163f0 (tracked)\n",
      "loss(X, Y) = 0.9453742f0 (tracked)\n",
      "loss(X, Y) = 0.86320263f0 (tracked)\n",
      "loss(X, Y) = 0.7916681f0 (tracked)\n",
      "loss(X, Y) = 0.73016065f0 (tracked)\n",
      "loss(X, Y) = 0.6777168f0 (tracked)\n",
      "loss(X, Y) = 0.63317394f0 (tracked)\n",
      "loss(X, Y) = 0.59533244f0 (tracked)\n",
      "loss(X, Y) = 0.5631112f0 (tracked)\n",
      "loss(X, Y) = 0.5354955f0 (tracked)\n",
      "loss(X, Y) = 0.5116075f0 (tracked)\n",
      "loss(X, Y) = 0.4907491f0 (tracked)\n",
      "loss(X, Y) = 0.47239485f0 (tracked)\n",
      "loss(X, Y) = 0.45614895f0 (tracked)\n",
      "loss(X, Y) = 0.44166607f0 (tracked)\n",
      "loss(X, Y) = 0.42867664f0 (tracked)\n",
      "loss(X, Y) = 0.4169545f0 (tracked)\n",
      "loss(X, Y) = 0.40630507f0 (tracked)\n",
      "loss(X, Y) = 0.39656532f0 (tracked)\n",
      "loss(X, Y) = 0.38760877f0 (tracked)\n",
      "loss(X, Y) = 0.37933645f0 (tracked)\n",
      "loss(X, Y) = 0.3716537f0 (tracked)\n",
      "loss(X, Y) = 0.36449382f0 (tracked)\n",
      "loss(X, Y) = 0.35779676f0 (tracked)\n",
      "loss(X, Y) = 0.35151023f0 (tracked)\n",
      "loss(X, Y) = 0.34559497f0 (tracked)\n",
      "loss(X, Y) = 0.34000674f0 (tracked)\n",
      "loss(X, Y) = 0.33471614f0 (tracked)\n",
      "loss(X, Y) = 0.32969463f0 (tracked)\n",
      "loss(X, Y) = 0.32491583f0 (tracked)\n",
      "loss(X, Y) = 0.32036152f0 (tracked)\n",
      "loss(X, Y) = 0.31601256f0 (tracked)\n",
      "loss(X, Y) = 0.3118546f0 (tracked)\n",
      "loss(X, Y) = 0.3078754f0 (tracked)\n",
      "loss(X, Y) = 0.30405965f0 (tracked)\n",
      "loss(X, Y) = 0.30039585f0 (tracked)\n",
      "loss(X, Y) = 0.29687303f0 (tracked)\n",
      "loss(X, Y) = 0.29347548f0 (tracked)\n",
      "loss(X, Y) = 0.29020098f0 (tracked)\n",
      "loss(X, Y) = 0.28704202f0 (tracked)\n",
      "loss(X, Y) = 0.28399003f0 (tracked)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9219666666666667"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200) |> gpu\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "@info \"starting training..\"\n",
    "Flux.train!(loss, dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "accuracy(X, Y)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Test set accuracy"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9219"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "\n",
    "accuracy(tX, tY)"
   ],
   "metadata": {},
   "execution_count": 5
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
