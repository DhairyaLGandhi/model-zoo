{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating registry at `~/.julia/registries/General`\n",
      "  Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h  Updating git-repo `https://github.com/JuliaGPU/CUDAdrv.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/JuliaGPU/CUDAnative.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/JuliaGPU/CuArrays.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/FluxML/Flux.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/text/phonemes/Manifest.toml`\n",
      " [no changes]\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg; Pkg.activate(\"/home/dhairyagandhi96/modelzoo/model-zoo/script/../text/phonemes\"); Pkg.instantiate(); Pkg.add(PackageSpec(name=\"CUDAdrv\", rev = \"master\")); Pkg.add(PackageSpec(name=\"CUDAnative\", rev = \"master\")); Pkg.add(PackageSpec(name=\"CuArrays\", rev = \"master\")); Pkg.add(PackageSpec(name=\"Flux\", rev = \"master\"))"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Based on https://arxiv.org/abs/1409.0473"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "using Flux: flip, crossentropy, reset!, throttle\n",
    "\n",
    "include(\"0-data.jl\")\n",
    "\n",
    "Nin = length(alphabet)\n",
    "Nh = 30 # size of hidden layer"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "A recurrent model which takes a token and returns a context-dependent\n",
    "annotation."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "align (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "forward  = LSTM(Nin, Nh÷2)\n",
    "backward = LSTM(Nin, Nh÷2)\n",
    "encode(tokens) = vcat.(forward.(tokens), flip(backward, tokens))\n",
    "\n",
    "alignnet = Dense(2Nh, 1)\n",
    "align(s, t) = alignnet(vcat(t, s .* trues(1, size(t, 2))))"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "A recurrent model which takes a sequence of annotations, attends, and returns\n",
    "a predicted output token."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "decode (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "recur   = LSTM(Nh+length(phones), Nh)\n",
    "toalpha = Dense(Nh, length(phones))\n",
    "\n",
    "function asoftmax(xs)\n",
    "  xs = [exp.(x) for x in xs]\n",
    "  s = sum(xs)\n",
    "  return [x ./ s for x in xs]\n",
    "end\n",
    "\n",
    "function decode1(tokens, phone)\n",
    "  weights = asoftmax([align(recur.state[2], t) for t in tokens])\n",
    "  context = sum(map((a, b) -> a .* b, weights, tokens))\n",
    "  y = recur(vcat(Float32.(phone), context))\n",
    "  return softmax(toalpha(y))\n",
    "end\n",
    "\n",
    "decode(tokens, phones) = [decode1(tokens, phone) for phone in phones]"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The full model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: ADAM(params) is deprecated; use ADAM(η::Float64) instead\n",
      "│   caller = top-level scope at none:0\n",
      "└ @ Core none:0\n",
      "┌ Warning: train!(loss, data, opt) is deprecated; use train!(loss, params, data, opt) instead\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n",
      "loss(data[500]...) = 31.0931f0 (tracked)\n",
      "loss(data[500]...) = 18.719795f0 (tracked)\n",
      "loss(data[500]...) = 16.85845f0 (tracked)\n",
      "loss(data[500]...) = 15.588554f0 (tracked)\n",
      "loss(data[500]...) = 15.574289f0 (tracked)\n",
      "loss(data[500]...) = 14.420161f0 (tracked)\n",
      "loss(data[500]...) = 13.901421f0 (tracked)\n",
      "loss(data[500]...) = 14.280205f0 (tracked)\n",
      "loss(data[500]...) = 13.549485f0 (tracked)\n",
      "loss(data[500]...) = 14.676176f0 (tracked)\n",
      "loss(data[500]...) = 14.110245f0 (tracked)\n",
      "loss(data[500]...) = 16.086271f0 (tracked)\n",
      "loss(data[500]...) = 15.810038f0 (tracked)\n",
      "loss(data[500]...) = 17.4217f0 (tracked)\n",
      "loss(data[500]...) = 18.87833f0 (tracked)\n",
      "loss(data[500]...) = 22.803078f0 (tracked)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "state = (forward, backward, alignnet, recur, toalpha)\n",
    "\n",
    "function model(x, y)\n",
    "  ŷ = decode(encode(x), y)\n",
    "  reset!(state)\n",
    "  return ŷ\n",
    "end\n",
    "\n",
    "loss(x, yo, y) = sum(crossentropy.(model(x, yo), y))\n",
    "\n",
    "evalcb = () -> @show loss(data[500]...)\n",
    "opt = ADAM(params(state))\n",
    "\n",
    "Flux.train!(loss, data, opt, cb = throttle(evalcb, 10))"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Prediction"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "15-element Array{Any,1}:\n :M  \n :EY2\n :T  \n :R  \n :IH2\n :S  \n :T  \n :AH0\n :S  \n :EY1\n :SH \n :AH0\n :NG \n :L  \n :IH0"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "using StatsBase: wsample\n",
    "\n",
    "function predict(s)\n",
    "  ts = encode(tokenise(s, alphabet))\n",
    "  ps = Any[:start]\n",
    "  for i = 1:50\n",
    "    dist = decode1(ts, onehot(ps[end], phones))\n",
    "    next = wsample(phones, vec(Tracker.data(dist)))\n",
    "    next == :end && break\n",
    "    push!(ps, next)\n",
    "  end\n",
    "  return ps[2:end]\n",
    "end\n",
    "\n",
    "predict(\"PHYLOGENY\")"
   ],
   "metadata": {},
   "execution_count": 6
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
