{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating registry at `~/.julia/registries/General`\n",
      "  Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h  Updating git-repo `https://github.com/JuliaGPU/CUDAdrv.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/JuliaGPU/CUDAnative.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/JuliaGPU/CuArrays.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Project.toml`\n",
      " [no changes]\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Manifest.toml`\n",
      " [no changes]\n",
      "  Updating git-repo `https://github.com/FluxML/Flux.jl.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Project.toml`\n",
      "  [587475ba] ↑ Flux v0.6.7 ⇒ v0.6.10+ #master (https://github.com/FluxML/Flux.jl.git)\n",
      "  Updating `~/modelzoo/model-zoo/other/bitstring-parity/Manifest.toml`\n",
      "  [79e6a3ab] ↑ Adapt v0.3.1 ⇒ v0.4.1\n",
      "  [587475ba] ↑ Flux v0.6.7 ⇒ v0.6.10+ #master (https://github.com/FluxML/Flux.jl.git)\n",
      "  [0c68f7d7] ↑ GPUArrays v0.5.0 ⇒ v0.6.0\n",
      "┌ Warning: ADAM(params) is deprecated; use ADAM(η::Float64) instead\n",
      "│   caller = top-level scope at none:0\n",
      "└ @ Core none:0\n",
      "┌ Warning: train!(loss, data, opt) is deprecated; use train!(loss, params, data, opt) instead\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n",
      "batch_loss(val) = 0.726842f0 (tracked)\n",
      "batch_loss(val) = 0.8017367f0 (tracked)\n",
      "batch_loss(val) = 0.8238425f0 (tracked)\n",
      "batch_loss(val) = 0.828543f0 (tracked)\n",
      "batch_loss(val) = 0.82635367f0 (tracked)\n",
      "batch_loss(val) = 0.81923676f0 (tracked)\n",
      "batch_loss(val) = 0.8036491f0 (tracked)\n",
      "batch_loss(val) = 0.7645098f0 (tracked)\n",
      "batch_loss(val) = 0.6554087f0 (tracked)\n",
      "batch_loss(val) = 0.45914063f0 (tracked)\n",
      "batch_loss(val) = 0.2791401f0 (tracked)\n",
      "batch_loss(val) = 0.163764f0 (tracked)\n",
      "batch_loss(val) = 0.10056899f0 (tracked)\n",
      "batch_loss(val) = 0.06649699f0 (tracked)\n",
      "batch_loss(val) = 0.046990912f0 (tracked)\n",
      "batch_loss(val) = 0.034983236f0 (tracked)\n",
      "batch_loss(val) = 0.027092542f0 (tracked)\n",
      "batch_loss(val) = 0.021623325f0 (tracked)\n",
      "batch_loss(val) = 0.017668325f0 (tracked)\n",
      "batch_loss(val) = 0.0147092445f0 (tracked)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg; Pkg.activate(\"/home/dhairyagandhi96/modelzoo/model-zoo/script/../other/bitstring-parity\"); Pkg.instantiate(); Pkg.add(PackageSpec(name=\"CUDAdrv\", rev = \"master\")); Pkg.add(PackageSpec(name=\"CUDAnative\", rev = \"master\")); Pkg.add(PackageSpec(name=\"CuArrays\", rev = \"master\")); Pkg.add(PackageSpec(name=\"Flux\", rev = \"master\"))\n",
    "\n",
    "include(\"data.jl\")\n",
    "using Flux, Statistics\n",
    "using Flux: onehot, onehotbatch, throttle, crossentropy, reset!, onecold\n",
    "\n",
    "const epochs = 20\n",
    "\n",
    "train = gendata(100, 2)\n",
    "val = gendata(10, 2)\n",
    "\n",
    "scanner = LSTM(length(alphabet), 20)\n",
    "encoder = Dense(20, length(alphabet))\n",
    "\n",
    "function model(x)\n",
    "    state = scanner.(x.data)[end]\n",
    "    reset!(scanner)\n",
    "    softmax(encoder(state))\n",
    "end\n",
    "\n",
    "loss(x, y) = crossentropy(model(x), y)\n",
    "batch_loss(data) = mean(loss(d...) for d in data)\n",
    "\n",
    "opt = ADAM(params(scanner, encoder))\n",
    "evalcb = () -> @show batch_loss(val)\n",
    "\n",
    "for i=1:epochs\n",
    "    Flux.train!(loss, train, opt, cb=throttle(evalcb, 10))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "sanity test"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0]\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "tx = map(c -> onehotbatch(c, alphabet), [\n",
    "    [false, true], # 01 -> 1\n",
    "    [true, false], # 10 -> 1\n",
    "    [false, false], # 00 -> 0\n",
    "    [true, true]]) # 11 -> 0\n",
    "[onecold(model(x)) - 1 for x in tx] |> println"
   ],
   "metadata": {},
   "execution_count": 2
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
