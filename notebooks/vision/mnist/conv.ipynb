{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status `~/temp/model-zoo/Project.toml`\n",
      "  [1520ce14]   AbstractTrees v0.2.1\n",
      "  [fbb218c0] ↑ BSON v0.2.3 ⇒ v0.2.4\n",
      "  [54eefc05]   Cascadia v0.4.0\n",
      "  [8f4d0f93]   Conda v1.3.0\n",
      "  [864edb3b] ↑ DataStructures v0.17.0 ⇒ v0.17.5\n",
      "  [31c24e10] ↑ Distributions v0.21.3 ⇒ v0.21.5\n",
      "  [587475ba]   Flux v0.9.0\n",
      "  [708ec375]   Gumbo v0.5.1\n",
      "  [b0807396]   Gym v1.1.3\n",
      "  [cd3eb016] ↑ HTTP v0.8.6 ⇒ v0.8.7\n",
      "  [6218d12a]   ImageMagick v0.7.5\n",
      "  [916415d5]   Images v0.18.0\n",
      "  [e5e0dc1b]   Juno v0.7.2\n",
      "  [ca7b5df7]   MFCC v0.3.1\n",
      "  [dbeba491] + Metalhead v0.4.0 #c4d1eba (https://github.com/FluxML/Metalhead.jl.git)\n",
      "  [91a5bcdd] ↑ Plots v0.26.3 ⇒ v0.27.0\n",
      "  [2913bbd2]   StatsBase v0.32.0\n",
      "  [98b73d46]   Trebuchet v0.1.0\n",
      "  [8149f6b0] ↑ WAV v1.0.2 ⇒ v1.0.3\n",
      "  [10745b16]   Statistics \n",
      "  [4ec0a83e]   Unicode \n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg; Pkg.activate(\"/home/dhairyagandhi96/temp/model-zoo/script/..\"); Pkg.status();"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Classifies MNIST digits with a convolutional network.\n",
    "Writes out saved model to the file \"mnist_conv.bson\".\n",
    "Demonstrates basic model construction, training, saving,\n",
    "conditional early-exit, and learning rate scheduling.\n",
    "\n",
    "This model, while simple, should hit around 99% test\n",
    "accuracy after training for approximately 20 epochs."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Load labels and images from Flux.Data.MNIST"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading data set\n",
      "└ @ Main.##827 string:1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60000-element Array{Array{ColorTypes.Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}:\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n ⋮                                                                                                                                                                                                                                                                               \n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "@info(\"Loading data set\")\n",
    "train_labels = MNIST.labels()\n",
    "train_imgs = MNIST.images()"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Bundle images together with labels and group into minibatchess"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "469-element Array{Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}},1}:\n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false true … false false; false false … false false; … ; false false … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; true false … false false; … ; false false … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … true false; … ; false false … false false; false false … false true])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … true false; … ; false false … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false true; false false … true false; … ; false false … false false; false false … false false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false false … true false; false true … false false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false true … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false false … false false; false false … false false])\n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false true … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [true false … false false; false false … false false; … ; false false … false true; false false … false false])  \n ⋮                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; true false … false false; false false … true false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false false … false false; false false … false true]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false false … false false; false false … false false])\n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false true; … ; false true … false false; false false … false false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false true; … ; false true … false false; false false … true false])   \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false true … false false; … ; false false … false false; false false … false false]) \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; true true … false false; false false … false false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … true false; … ; false false … false false; true false … false false])  \n ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [false false … false false; false false … false false; … ; false false … false true; false false … false false]) "
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "batch_size = 128\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs]"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Prepare test set as one giant minibatch:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\nFloat32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\nFloat32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\n...\n\nFloat32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\nFloat32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n\nFloat32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[false false … false false; false false … false false; … ; false false … false false; false false … false false])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "test_imgs = MNIST.images(:test)\n",
    "test_labels = MNIST.labels(:test)\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs))"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Define our model.  We will use a simple convolutional architecture with\n",
    "three iterations of Conv -> ReLU -> MaxPool, followed by a final Dense\n",
    "layer that feeds into a softmax probability output."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Constructing model...\n",
      "└ @ Main.##827 string:1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(Conv((3, 3), 1=>16, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), getfield(Main.##827, Symbol(\"##3#4\"))(), Dense(288, 10), NNlib.softmax)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N)\n",
    "    # which is where we get the 288 in the `Dense` layer below:\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "    # Finally, softmax to get nice probabilities\n",
    "    softmax,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Load model and datasets onto GPU, if enabled"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(Conv((3, 3), 1=>16, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), getfield(Main.##827, Symbol(\"##3#4\"))(), Dense(288, 10), NNlib.softmax)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "train_set = gpu.(train_set)\n",
    "test_set = gpu.(test_set)\n",
    "model = gpu(model)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Make sure our model is nicely precompiled before starting our training loop"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Tracked 10×128 CuArrays.CuArray{Float32,2}:\n 0.00255751  0.00119594  0.0168251    0.0606279   …  0.00551574   0.0159382  \n 0.775642    0.974112    0.915527     0.54861        0.763186     0.77419    \n 0.00225806  0.00079201  0.0155177    0.0164719      0.00102728   0.00201624 \n 5.15309e-5  4.61399e-6  0.000362887  0.00034864     0.000153118  9.38692e-5 \n 0.214283    0.019429    0.0292266    0.328777       0.177665     0.179638   \n 4.79156e-5  2.98199e-5  0.00010558   0.00227185  …  2.06607e-5   0.000116079\n 0.00207104  6.94806e-5  0.0117128    0.00508135     0.00126504   0.000294191\n 4.08255e-5  3.38904e-6  0.000715339  0.00152151     2.17018e-5   0.000440877\n 0.0029698   0.00434108  0.009405     0.0349545      0.0510874    0.0271616  \n 7.79647e-5  2.2828e-5   0.000602114  0.00133604     5.74007e-5   0.000110899"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "model(train_set[1][1])"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "`loss()` calculates the crossentropy loss between our prediction `y_hat`\n",
    "(calculated from `model(x)`) and the ground truth `y`.  We augment the data\n",
    "a bit, adding gaussian random noise to our image to make it more robust."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "accuracy (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "function loss(x, y)\n",
    "    # We augment `x` a little bit here, adding in random noise\n",
    "    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Train our model with the given training set using the ADAM optimizer and\n",
    "printing out performance against the test set as we go."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main.##827 string:3\n",
      "┌ Info: [1]: Test accuracy: 0.9584\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [2]: Test accuracy: 0.9713\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [3]: Test accuracy: 0.9792\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [4]: Test accuracy: 0.9814\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [5]: Test accuracy: 0.9844\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [6]: Test accuracy: 0.9850\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [7]: Test accuracy: 0.9836\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [8]: Test accuracy: 0.9846\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [9]: Test accuracy: 0.9859\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [10]: Test accuracy: 0.9870\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [11]: Test accuracy: 0.9861\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [12]: Test accuracy: 0.9869\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [13]: Test accuracy: 0.9863\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [14]: Test accuracy: 0.9887\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [15]: Test accuracy: 0.9880\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [16]: Test accuracy: 0.9878\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [17]: Test accuracy: 0.9875\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [18]: Test accuracy: 0.9853\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [19]: Test accuracy: 0.9878\n",
      "└ @ Main.##827 string:12\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "└ @ Main.##827 string:28\n",
      "┌ Info: [20]: Test accuracy: 0.9898\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [21]: Test accuracy: 0.9897\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [22]: Test accuracy: 0.9895\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [23]: Test accuracy: 0.9898\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [24]: Test accuracy: 0.9897\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [25]: Test accuracy: 0.9898\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [26]: Test accuracy: 0.9895\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [27]: Test accuracy: 0.9900\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [28]: Test accuracy: 0.9896\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [29]: Test accuracy: 0.9896\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [30]: Test accuracy: 0.9893\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [31]: Test accuracy: 0.9899\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [32]: Test accuracy: 0.9895\n",
      "└ @ Main.##827 string:12\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "└ @ Main.##827 string:28\n",
      "┌ Info: [33]: Test accuracy: 0.9899\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [34]: Test accuracy: 0.9901\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [35]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [36]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [37]: Test accuracy: 0.9905\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main.##827 string:20\n",
      "┌ Info: [38]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [39]: Test accuracy: 0.9904\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [40]: Test accuracy: 0.9904\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [41]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [42]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "└ @ Main.##827 string:28\n",
      "┌ Info: [43]: Test accuracy: 0.9904\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [44]: Test accuracy: 0.9904\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [45]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [46]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [47]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "└ @ Main.##827 string:28\n",
      "┌ Info: [48]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [49]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [50]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [51]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [52]: Test accuracy: 0.9903\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [53]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [54]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [55]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [56]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Info: [57]: Test accuracy: 0.9902\n",
      "└ @ Main.##827 string:12\n",
      "┌ Warning:  -> We're calling this converged.\n",
      "└ @ Main.##827 string:34\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "opt = ADAM(0.001)\n",
    "\n",
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    global best_acc, last_improvement\n",
    "    # Train for a single epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to mnist_conv.bson\")\n",
    "        BSON.@save joinpath(dirname(@__FILE__), \"mnist_conv.bson\") model epoch_idx acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 10
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "kernelspec": {
   "name": "julia-1.1",
   "display_name": "Julia 1.1.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
