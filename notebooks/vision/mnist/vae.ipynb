{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating registry at `~/.julia/registries/General`\n",
      "  Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l    Fetching: [>                                        ]  0.0 %\r\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate();\n",
    "\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: throttle, params\n",
    "using Juno: @progress"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Extend distributions slightly to have a numerically stable logpdf for `p` close to 1 or 0."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using Distributions.params in module ##358 conflicts with an existing identifier.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "logpdf (generic function with 62 methods)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "using Distributions\n",
    "import Distributions: logpdf\n",
    "logpdf(b::Bernoulli, y::Bool) = y * log(b.p + eps()) + (1 - y) * log(1 - b.p + eps())"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Load data, binarise it, and partition into mini-batches of M."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "600-element Array{BitArray{2},1}:\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n ⋮                                                                                                               \n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]\n [false false … false false; false false … false false; … ; false false … false false; false false … false false]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "X = float.(hcat(vec.(MNIST.images())...)) .> 0.5\n",
    "N, M = size(X, 2), 100\n",
    "data = [X[:,i] for i in Iterators.partition(1:N,M)]\n",
    "\n",
    "\n",
    "################################# Define Model #################################"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Latent dimensionality, # hidden units."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, 500)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "Dz, Dh = 5, 500"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Components of recognition model / \"encoder\" MLP."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "z (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "A, μ, logσ = Dense(28^2, Dh, tanh), Dense(Dh, Dz), Dense(Dh, Dz)\n",
    "g(X) = (h = A(X); (μ(h), logσ(h)))\n",
    "z(μ, logσ) = μ + exp(logσ) * randn()"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Generative model / \"decoder\" MLP."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(Dense(5, 500, tanh), Dense(500, 784, NNlib.σ))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "f = Chain(Dense(Dz, Dh, tanh), Dense(Dh, 28^2, σ))\n",
    "\n",
    "\n",
    "####################### Define ways of doing things with the model. #######################"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "KL-divergence between approximation posterior and N(0, 1) prior."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "kl_q_p (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "kl_q_p(μ, logσ) = 0.5 * sum(exp.(2 .* logσ) + μ.^2 .- 1 .+ logσ.^2)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "logp(x|z) - conditional probability of data given latents."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "logp_x_z (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "logp_x_z(x, z) = sum(logpdf.(Bernoulli.(f(z)), x))"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Monte Carlo estimator of mean ELBO using M samples."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "loss (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "L̄(X) = ((μ̂, logσ̂) = g(X); (logp_x_z(X, z.(μ̂, logσ̂)) - kl_q_p(μ̂, logσ̂)) / M)\n",
    "\n",
    "loss(X) = -L̄(X) + 0.01 * sum(x->sum(x.^2), params(f))"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Sample from the learned model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 543.1589636480705 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 208.7558564799027 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 188.01054312972693 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 177.620175332416 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 181.41586825699696 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 177.64052726653924 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 162.65382475999098 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 170.40689285327417 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 165.3394833974157 (tracked)\n",
      "┌ Info: Epoch 2\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 169.30139679989122 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 170.56885601617753 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 165.88201025958278 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 161.77510983855007 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 159.3024751808574 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 163.6701361629169 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 160.26310338500895 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 158.91966299736671 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 152.1355363026957 (tracked)\n",
      "┌ Info: Epoch 3\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 159.37097558355444 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 149.0496946378027 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 156.02746368650426 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 150.54952215500325 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 144.10694429277729 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 146.83342429294615 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 157.87267313269615 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 150.1430832335312 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 150.7882915745878 (tracked)\n",
      "┌ Info: Epoch 4\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 151.6698078242667 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 144.17654636484897 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 148.41988017993575 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.9538515541531 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 152.92480432023848 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.83305987494242 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 149.56885002092775 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.716006463715 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 146.93094991529526 (tracked)\n",
      "┌ Info: Epoch 5\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 144.26403892876786 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 150.28456568935246 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 137.14557388935108 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 154.2427051163004 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.34948613546027 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.64278665371066 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 143.92674522220992 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 150.14621513430532 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 140.323022090835 (tracked)\n",
      "┌ Info: Epoch 6\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.11245438024213 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 142.98827963852634 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 147.9951491741226 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 134.25665838442464 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 136.99793141416205 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 142.3284421032785 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 151.17245821694317 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.47906962400558 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 138.05040544639226 (tracked)\n",
      "┌ Info: Epoch 7\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 152.8277383642757 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.78477198338823 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 143.0761298147209 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 143.5056801713942 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 148.0706593489878 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 140.6432850855518 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 137.9897063028286 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.93683401703373 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 147.4816999744432 (tracked)\n",
      "┌ Info: Epoch 8\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 137.04814253725047 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 144.39576704394537 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 147.24445260165467 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 147.27742743781636 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 143.5811038252154 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.02394316640328 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 143.3441466600462 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 142.83519344082492 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 142.62506868723503 (tracked)\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 134.05395749562732 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 136.70545396584973 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 147.39455202193025 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 142.75252139099 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.93323097107515 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 136.41168408118926 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.8095257447019 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 136.93507515493195 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 148.64763183445487 (tracked)\n",
      "┌ Info: Epoch 10\n",
      "└ @ Main.##358 string:9\n",
      "-(L̄(X[:, rand(1:N, M)])) = 139.63956014576397 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 137.1728306196579 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 138.9304868482466 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 141.706213643708 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 149.47570173875025 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 146.60057802444524 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 145.5792450428126 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 146.16990790224276 (tracked)\n",
      "-(L̄(X[:, rand(1:N, M)])) = 137.8631329146337 (tracked)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "modelsample() = rand.(Bernoulli.(f(z.(zeros(Dz), zeros(Dz)))))\n",
    "\n",
    "\n",
    "################################# Learn Parameters ##############################\n",
    "\n",
    "evalcb = throttle(() -> @show(-L̄(X[:, rand(1:N, M)])), 30)\n",
    "opt = ADAM(params(A, μ, logσ, f))\n",
    "@progress for i = 1:10\n",
    "  @info \"Epoch $i\"\n",
    "  Flux.train!(loss, zip(data), opt, cb=evalcb)\n",
    "end\n",
    "\n",
    "\n",
    "################################# Sample Output ##############################\n",
    "\n",
    "#using Images\n",
    "\n",
    "#img(x) = Gray.(reshape(x, 28, 28))\n",
    "\n",
    "#cd(@__DIR__)\n",
    "#sample = hcat(img.([modelsample() for i = 1:10])...)\n",
    "#save(\"sample.png\", sample)"
   ],
   "metadata": {},
   "execution_count": 10
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
